{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "H-HZQC1NgqDl"
   },
   "outputs": [],
   "source": [
    "#PERCEPTRON FOR OR GATE\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Perceptron:\n",
    "    def __init__(self, max_iters=100):\n",
    "        self.max_iters = max_iters\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        X, y = np.asarray(X), np.asarray(y)\n",
    "        iters = 0\n",
    "        \n",
    "        X = np.concatenate((X, np.asarray([[1] * X.shape[0]]).T), axis=1)\n",
    "        \n",
    "        ω = np.random.random(X.shape[1])        \n",
    "        \n",
    "        for _ in range(self.max_iters):\n",
    "            y_pred_all = []\n",
    "            for idx in range(X.shape[0]):\n",
    "                x_sample, y_sample = X[idx], y[idx]\n",
    "                y_pred = int(np.sum(ω * x_sample) >= 0.5)\n",
    "                if y_pred == y_sample:\n",
    "                    pass\n",
    "                elif y_pred == 0 and y_sample == 1:\n",
    "                    ω = ω + x_sample\n",
    "                elif y_pred == 1 and y_sample == 0:\n",
    "                    ω = ω - x_sample\n",
    "                \n",
    "                y_pred_all.append(y_pred)\n",
    "            \n",
    "            iters += 1\n",
    "            if np.equal(np.array(y_pred_all), y).all():\n",
    "                break\n",
    "                \n",
    "        self.iters, self.ω = iters, ω\n",
    "        \n",
    "    def predict(self, X):\n",
    "        X = np.asarray(X)\n",
    "        X = np.concatenate((X, np.asarray([[1] * X.shape[0]]).T), axis=1)\n",
    "        \n",
    "        return (X @ self.ω > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "UkJPpCmbgx46"
   },
   "outputs": [],
   "source": [
    "clf = Perceptron()\n",
    "clf.fit([[1], [2], [3]], [0, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ou8p4FSvgz5q",
    "outputId": "ded03205-01d2-4d81-ebcc-f8c457e4e449"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.iters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LsnorfrYg1vi",
    "outputId": "ab76640f-c098-456b-b436-4718b525af8a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([[1], [2], [3]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "zLpOwUKpg6za"
   },
   "outputs": [],
   "source": [
    "clf = Perceptron()\n",
    "clf.fit([[1], [2], [3]], [0, 1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HgYm4tZxg8iK",
    "outputId": "350465fe-c892-49bf-fb5b-d38bf06e1dc6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tt-fPa36g_Li",
    "outputId": "a2240d5c-9b5d-4290-d6e9-6113e4c82cd9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([[1], [2], [3]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "YzpujdFon4U-"
   },
   "outputs": [],
   "source": [
    "#ADALINE FOR OR GATE\n",
    "\n",
    "def adaline(outputs, weights, bias):\n",
    "    total_error = 1\n",
    "    counter = 0\n",
    "    while total_error != 0 and counter < 10:\n",
    "\n",
    "        total_error = 0\n",
    "        counter += 1\n",
    "        for i in range(len(outputs)):\n",
    "            sum = INPUTS[i].dot(weights) + bias\n",
    "            prediction = step_function(sum)\n",
    "\n",
    "            total_error += outputs[i] - prediction\n",
    "            error = outputs[i] - sum\n",
    "\n",
    "            if outputs[i] != prediction:\n",
    "                weights[0] = weights[0] + (LEARNING_RATE * error * INPUTS[i][0])\n",
    "                weights[1] = weights[1] + (LEARNING_RATE * error * INPUTS[i][1])\n",
    "                bias = bias + (LEARNING_RATE * error)\n",
    "                print(\"Weight updated: \" + str(weights[0]))\n",
    "                print(\"Weight updated: \" + str(weights[1]))\n",
    "                print(\"Bias updated`: \" + str(bias))\n",
    "                print(\"----------------------------------------\")\n",
    "\n",
    "        print(\"Total error: \" + str(total_error))\n",
    "        print(\"----------------------------------------\")\n",
    "\n",
    "    return weights, bias"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "19BCE1688_LAB4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
